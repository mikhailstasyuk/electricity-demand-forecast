{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_db(\n",
    "    tabname: str,\n",
    "    dbname: str,\n",
    "    schema: list,\n",
    "    user: str,\n",
    "    password: str,\n",
    "    host: int,\n",
    "    port: int,\n",
    "    connect_timeout: int\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    DATABASE_URL = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "    try:\n",
    "        engine = create_engine(DATABASE_URL, connect_args={'connect_timeout': connect_timeout})\n",
    "    except:\n",
    "        print(\"Failed to establish connection to the database.\")\n",
    "\n",
    "    schema_str = \",\".join(schema)\n",
    "    query = text(f'SELECT {schema_str} FROM {tabname};')\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql_query(query, conn).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_iqr(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter DataFrame using the Interquartile Range (IQR) method.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the \"value\" column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    # Compute the IQR for the \"value\" column\n",
    "    Q1 = df['value'].quantile(0.25)\n",
    "    Q3 = df['value'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define bounds for the acceptable range\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Remove rows where the \"value\" column is outside the bounds.\n",
    "    filt = (df['value'] >= lower_bound) & (df['value'] <= upper_bound)\n",
    "    df_filtered = df[filt]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "        df: pd.DataFrame,\n",
    "        window_size=7,\n",
    "        inference=False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract date-related and rolling statistics features from DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'period' and 'value' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added date features and rolling stats.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['period'] = df['period'].astype('datetime64[ns]')\n",
    "    df['timezone'] = df['timezone'].astype('category')\n",
    "    df['value'] = df['value'].astype('int64')\n",
    "\n",
    "    # Separate date features\n",
    "    df['year'] = df['period'].dt.year.astype('uint16')\n",
    "    df['month'] = df['period'].dt.month.astype('uint16')\n",
    "    df['day'] = df['period'].dt.day.astype('uint16')\n",
    "\n",
    "    # Extract the day of the week\n",
    "    df['day_of_week'] = df['period'].dt.day_name().astype('category')\n",
    "\n",
    "    # Extract quarterly and weekly information to capture seasonality\n",
    "    df['quarter'] = df['period'].dt.quarter.astype('uint8')\n",
    "    df['week_of_year'] = df['period'].dt.isocalendar().week.astype('uint16')\n",
    "\n",
    "    # Mark the weekends\n",
    "    df['is_weekend'] = (df['period'].dt.weekday >= 5).astype('uint8')\n",
    "    \n",
    "    if not inference:\n",
    "        # Create rolling mean feature\n",
    "        df['rolling_mean'] = df['value'].rolling(window=window_size).mean()\n",
    "    \n",
    "        # Create rolling standard deviation feature\n",
    "        df['rolling_std'] = df['value'].rolling(window=window_size).std()\n",
    "    \n",
    "    # Remove NaNs introduced by the rolling mean and std\n",
    "    df = df.dropna().copy().reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_supervised(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform DataFrame into a supervised learning format.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'lag' column and 'period' dropped.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create 'lag' column by shifting 'value' column\n",
    "    df.loc[:, 'lag'] = df['value'].shift()\n",
    "\n",
    "    # Remove rows with missing values (NaN) due to the shift\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Convert 'lag' column to unsigned 64-bit integer type\n",
    "    df.lag = df.lag.astype('uint64')\n",
    "\n",
    "    # Drop the 'period' column from the DataFrame\n",
    "    df = df.drop(columns=['period'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df: pd.DataFrame, ohe=None, fit=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode categorical columns as dummy variables.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with categorical columns encoded as dummy variables.\n",
    "    \"\"\" \n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    if ohe == None:\n",
    "        ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # List of columns to encode as dummy variables\n",
    "    feat_to_enc = df.select_dtypes('category')\n",
    "\n",
    "    # Get dummy variables for the specified columns\n",
    "    if fit == True:\n",
    "        dummies = pd.DataFrame(ohe.fit_transform(feat_to_enc))\n",
    "    else:\n",
    "        dummies = pd.DataFrame(ohe.transform(feat_to_enc))\n",
    "    dummies.columns = ohe.get_feature_names_out()\n",
    "    \n",
    "    # Concatenate the dummy variables with the original DataFrame\n",
    "    df = pd.concat((df.drop(columns=feat_to_enc.columns), dummies), axis=1)\n",
    "    return df, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    schema = ['period', 'timezone', 'value']\n",
    "    tabname = 'demand'\n",
    "    conn_params = {\n",
    "    'tabname': tabname,\n",
    "    'dbname': 'db_demand',\n",
    "    'schema': schema,\n",
    "    'user': 'dbuser',\n",
    "    'password': '123',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'connect_timeout': 5\n",
    "    }\n",
    "\n",
    "    df = read_from_db(**conn_params)\n",
    "    \n",
    "    # Clean it up, extract date features and running statistics.\n",
    "    df_no_outliers = filter_by_iqr(df)\n",
    "    df_newfeat= extract_features(df_no_outliers)\n",
    "    \n",
    "    # Preprocess the dataset for model input.\n",
    "    df_transformed = transform_to_supervised(df_newfeat)\n",
    "    df_encoded, ohe = encode_categorical(df_transformed)\n",
    "    return df_encoded, ohe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
