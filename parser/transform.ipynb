{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import optuna\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/2018-01-01-2022-01-01.bin'\n",
    "\n",
    "cols_to_drop = ['subba-name', 'parent', 'parent-name', 'value-units']\n",
    "\n",
    "dtypes = {'period': 'datetime64',\n",
    "          'subba': 'category',\n",
    "          'timezone': 'category',\n",
    "          'value': 'uint64'}\n",
    "\n",
    "df = pd.read_pickle(filename).drop(columns=cols_to_drop)\n",
    "df = df.drop_duplicates().dropna().reset_index(drop=True)\n",
    "df = df.astype(dtypes)\n",
    "\n",
    "df = df[df['subba'] == 'ZONJ']\n",
    "print('df shape:', df.shape)\n",
    "print(df.head(1))\n",
    "print(df.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = df.value == 0\n",
    "to_drop = df[filt].index\n",
    "df = df.drop(index=to_drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='period').plot(x='period', y='value', figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the IQR for the \"value\" column\n",
    "Q1 = df['value'].quantile(0.25)\n",
    "Q3 = df['value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds for the acceptable range\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove rows where the value in the \"value\" column is outside the bounds\n",
    "df_filtered = df[(df['value'] >= lower_bound) & (df['value'] <= upper_bound)]\n",
    "\n",
    "print(df_filtered)\n",
    "\n",
    "# Plotting\n",
    "df_filtered.plot(x='period', y='value', kind='line')\n",
    "\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Value over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort df by date in ascending order\n",
    "df_sorted = df.sort_values(by=['period']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    # Separate date features\n",
    "    df['year'] = df['period'].dt.year.astype('uint16')\n",
    "    df['month'] = df['period'].dt.month.astype('uint16')\n",
    "    df['day'] = df['period'].dt.day.astype('uint16')\n",
    "\n",
    "    # Extract the day of the week\n",
    "    df['day_of_week'] = df['period'].dt.day_name()\n",
    "\n",
    "    # Extract quarterly and weekly information to capture seasonality\n",
    "    df['quarter'] = df['period'].dt.quarter.astype('uint8')\n",
    "    df['week_of_year'] = df['period'].dt.isocalendar().week.astype('uint16')\n",
    "\n",
    "    # Mark the weekends\n",
    "    df['is_weekend'] = (df['period'].dt.weekday >= 5).astype('uint8')\n",
    "    \n",
    "    window_size = 7 # 7-day window\n",
    "\n",
    "    # Create rolling mean feature\n",
    "    df['rolling_mean_7'] = df['value'].rolling(window=window_size).mean()\n",
    "\n",
    "    # Create rolling standard deviation feature\n",
    "    df['rolling_std_7'] = df['value'].rolling(window=window_size).std()\n",
    "    \n",
    "    # Remove NaNs introduced by the rolling mean and std\n",
    "    df = df.dropna().copy().reset_index(drop=True)\n",
    "\n",
    "    # Create a random feature as a threshold for later feature filtering\n",
    "    random_feature = [random.random() for _ in range(df.shape[0])]\n",
    "    df['random_feature'] = random_feature\n",
    "    return df\n",
    "\n",
    "df_newfeat = extract_features(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_supervised(df):\n",
    "    print(df.columns.tolist())\n",
    "    df.loc[:, 'lag'] = df['value'].shift()\n",
    "    df.dropna(inplace=True)\n",
    "    df.lag = df.lag.astype('uint64')\n",
    "    df = df.drop(columns=['period'])\n",
    "    return df\n",
    "\n",
    "def encode_categorical(df):\n",
    "    cols_to_enc = ['timezone', 'day_of_week']\n",
    "\n",
    "    dummies = pd.get_dummies(df[cols_to_enc])\n",
    "    df_encoded = pd.concat((dummies, df.drop(columns=cols_to_enc)), axis=1)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for feeding it into the model\n",
    "df_transformed = transform_to_supervised(df_newfeat)\n",
    "df_transformed\n",
    "df_encoded = encode_categorical(df_transformed).drop(columns=['subba'])\n",
    "print(df_encoded.shape)\n",
    "df_encoded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['value'])\n",
    "y = df_encoded.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 9\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y):\n",
    "    mae_train_hist = []\n",
    "    mae_test_hist = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        \n",
    "        mae_train_hist.append(mae_train)\n",
    "        mae_test_hist.append(mae_test)\n",
    "\n",
    "    mae_train_avg = sum(mae_train_hist) / len(mae_train_hist)\n",
    "    mae_test_avg = sum(mae_test_hist) / len(mae_test_hist)\n",
    "    return (mae_train_avg, mae_test_avg)\n",
    "\n",
    "mae_train_avg, mae_test_avg = train(model, X, y)\n",
    "print(f'Average mae on {n_splits} splits:\\nTrain: {mae_train_avg} | Test: {mae_test_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = model.feature_importances_\n",
    "cols = X.columns.tolist().copy()\n",
    "feat_imps = pd.DataFrame((cols, imp)).T\n",
    "feat_imps.columns = ['feature', 'importance']\n",
    "feat_imps.sort_values(by=['importance'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = feat_imps[feat_imps['feature'] == 'random_feature']['importance']\n",
    "redundant_col = feat_imps[feat_imps['importance'] < threshold.iloc[0]]\n",
    "to_drop = redundant_col['feature'].tolist() + ['random_feature']\n",
    "X_new = X.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
    "mae_test_avg = train(model, X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = to_drop + ['value']\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = df_encoded.iloc[-1:]\n",
    "test_row = test_row.drop(columns=cols_to_drop)\n",
    "test_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 2, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'alpha': trial.suggest_float(\"alpha\", 1e-5, 10, log=True),  \n",
    "        'gamma': trial.suggest_float(\"gamma\", 1e-5, 5, log=True),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-5, 10.0, log=True),\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    mae_train_avg, mae_test_avg = train(model, X_new, y)\n",
    "    return mae_test_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the study, the objective function is passed in as the first argument\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "print('Number of finished trials: ', len(study.trials))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Value: ', trial.value)\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = trial.params\n",
    "model = XGBRegressor(**best_params)\n",
    "train(model, X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
