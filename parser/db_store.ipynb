{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "from psycopg2.errors import DuplicateTable, OperationalError, UniqueViolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    \"\"\"Parse command line arguments.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        args (argparse.Namespace) : Arguments object\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('-k', '--api_key', type=str, help=\"API key to use\", required=True)\n",
    "    parser.add_argument('-sd', '--start', type=str, help=\"Start date y-m-d\", required=True)\n",
    "    parser.add_argument('-ed', '--end', type=str, help=\"End date y-m-d\", required=True)\n",
    "\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "    return args "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_data(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:  # Success\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(\n",
    "    tab_name: str,\n",
    "    tab_schema: str,\n",
    "    dbname: str,\n",
    "    user: str,\n",
    "    password: str,\n",
    "    host: int,\n",
    "    port: int,\n",
    "    connect_timeout: int\n",
    ") -> None:\n",
    "    \n",
    "    conn_params = {\n",
    "        'dbname': dbname,\n",
    "        'user': user,\n",
    "        'password': password,\n",
    "        'host': host,\n",
    "        'port': port,\n",
    "        'connect_timeout': connect_timeout\n",
    "    }\n",
    "    \n",
    "    # Connect to your postgres DB\n",
    "    try:\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "    \n",
    "    except OperationalError as e:\n",
    "        raise OperationalError(f\"Error connecting to the database: {e}\")\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Define the CREATE TABLE statement\n",
    "    create_table_query = f'''\n",
    "    CREATE TABLE {tab_name} (\n",
    "        id SERIAL PRIMARY KEY, \n",
    "        {tab_schema}\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        # Execute the query\n",
    "        cur.execute(create_table_query)\n",
    "\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "    except DuplicateTable as e:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        raise DuplicateTable(f\"The table {tab_name} already exists.\")\n",
    "    \n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_create_table(params, key, tab_schemas):\n",
    "    try:\n",
    "        tab_name, tab_schema = key, tab_schemas.get(key, -1)\n",
    "        params['tab_name'] = tab_name\n",
    "        params['tab_schema'] = tab_schema\n",
    "\n",
    "        create_table(**params)\n",
    "    except DuplicateTable as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_table(\n",
    "    data: list,\n",
    "    schema: list,\n",
    "    tab_name: str,\n",
    "    dbname: str,\n",
    "    user: str,\n",
    "    password: str,\n",
    "    host: int,\n",
    "    port: int,\n",
    "    connect_timeout: int\n",
    ") -> None:\n",
    "    \n",
    "    conn_params = {\n",
    "        'dbname': dbname,\n",
    "        'user': user,\n",
    "        'password': password,\n",
    "        'host': host,\n",
    "        'port': port,\n",
    "        'connect_timeout': connect_timeout\n",
    "    }\n",
    "    \n",
    "    # Connect to your postgres DB\n",
    "    try:\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "    \n",
    "    except OperationalError as e:\n",
    "        raise OperationalError(f\"Error connecting to the database: {e}\")\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Insert data\n",
    "    extras.execute_values(\n",
    "        cur,\n",
    "        f\"\"\"INSERT INTO {tab_name} ({schema}) \n",
    "        VALUES %s\n",
    "        ON CONFLICT ({schema})\n",
    "        DO NOTHING;\"\"\",\n",
    "        data\n",
    "    )\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_schemas = {\n",
    "    'demand': \n",
    "        '''\n",
    "        period VARCHAR(100),\n",
    "        subba VARCHAR(100),\n",
    "        subba_name VARCHAR(100),\t\n",
    "        parent VARCHAR(100),\t\n",
    "        parent_name VARCHAR(100),\t\n",
    "        timezone VARCHAR(100),\t\n",
    "        value INTEGER,\t\n",
    "        value_units VARCHAR(100),\n",
    "        UNIQUE (period, subba, subba_name, parent, parent_name, timezone, value, value_units)\n",
    "        ''',\n",
    "\n",
    "    'weather_hist':\n",
    "        '''\n",
    "        time VARCHAR(100) UNIQUE,\n",
    "        weathercode INTEGER,\n",
    "        temperature_2m_max\tREAL,\n",
    "        temperature_2m_min\tREAL,\n",
    "        temperature_2m_mean REAL,\n",
    "        UNIQUE (time, weathercode, temperature_2m_max, temperature_2m_min, temperature_2m_mean)\n",
    "        ''',\n",
    "\n",
    "    'weather_latest':\n",
    "        '''\n",
    "        time VARCHAR(100) UNIQUE, \n",
    "        temperature_2m_max REAL, \n",
    "        temperature_2m_min REAL, \n",
    "        UNIQUE (time,  temperature_2m_max, temperature_2m_min)\n",
    "        '''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_url(api, params):\n",
    "    start_date = params.get('start_date', None)\n",
    "    end_date = params.get('end_date', None)\n",
    "    offset = params.get('offset', None)\n",
    "    chunk_len = params.get('chunk_len', None)\n",
    "    api_key = params.get('api_key', None)\n",
    "\n",
    "    if api == 'demand':\n",
    "        url = f'https://api.eia.gov/v2/electricity/rto/' +\\\n",
    "        f'daily-region-sub-ba-data/data/?frequency=daily&data[0]=value' + \\\n",
    "        f'&facets[subba][]=ZONJ&start={start_date}&end={end_date}' + \\\n",
    "        f'&sort[0][column]=period&sort[0][direction]=asc&offset={offset}' + \\\n",
    "        f'&length={chunk_len}&api_key={api_key}'\n",
    "\n",
    "    elif api == 'weather_hist':\n",
    "        url = f'https://archive-api.open-meteo.com/v1' + \\\n",
    "        f'/archive?latitude=52.52&longitude=13.41&start_date={start_date}' + \\\n",
    "        f'&end_date={end_date}&daily=weathercode,temperature_2m_max,' + \\\n",
    "        f'temperature_2m_min,temperature_2m_mean' + \\\n",
    "        f'&timezone=America%2FNew_York'\n",
    "\n",
    "    elif api == 'weather_latest':\n",
    "        url = f'https://api.open-meteo.com/v1/forecast?' + \\\n",
    "        f'latitude=52.52&longitude=13.41&hourly=temperature_2m&daily=' + \\\n",
    "        f'temperature_2m_max,temperature_2m_min&timezone=America%2F' + \\\n",
    "        f'New_York&past_days=7'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python script\n",
    "# args = parse_arguments()\n",
    "# api_key = args.api_key\n",
    "# start_date = args.start\n",
    "# end_date = args.end\n",
    "\n",
    "# Notebook\n",
    "api_key = ''\n",
    "start_date = '2018-06-01'\n",
    "end_date = '2023-07-30'\n",
    "\n",
    "general_params = {\n",
    "    'dbname': 'db_demand',\n",
    "    'user': 'dbuser',\n",
    "    'password': '123',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'connect_timeout': 5\n",
    "} \n",
    "\n",
    "create_params = {\n",
    "    'tab_name': None,\n",
    "    'tab_schema': None,\n",
    "    'dbname': general_params['dbname'],\n",
    "    'user':  general_params['user'],\n",
    "    'password':  general_params['password'],\n",
    "    'host':  general_params['host'],\n",
    "    'port':  general_params['port'],\n",
    "    'connect_timeout': general_params['connect_timeout']\n",
    "}\n",
    "\n",
    "populate_params = {\n",
    "    'data': None,\n",
    "    'schema': None,\n",
    "    'tab_name': None,\n",
    "    'dbname': general_params['dbname'],\n",
    "    'user':  general_params['user'],\n",
    "    'password':  general_params['password'],\n",
    "    'host':  general_params['host'],\n",
    "    'port':  general_params['port'],\n",
    "    'connect_timeout': general_params['connect_timeout']\n",
    "}\n",
    "\n",
    "request_params = {\n",
    "    'api_key': api_key,\n",
    "    'start_date': start_date,\n",
    "    'end_date': end_date,\n",
    "    'chunk_len': 5000,\n",
    "    'offset': 0\n",
    "}\n",
    "apis = ['demand', 'weather_hist', 'weather_latest']\n",
    "\n",
    "duplicates_msg = 'Error: Data already exists during storage attempt.'\n",
    "\n",
    "def main():\n",
    "    for api in apis:\n",
    "        url = construct_url(api, request_params)\n",
    "        data = request_data(url)\n",
    "        if data:\n",
    "            if api == 'demand':\n",
    "                total_rows = data['response']['total']\n",
    "                print(\"Total rows:\", total_rows)\n",
    "                chunk_len = request_params.get('chunk_len', None)\n",
    "                total_chunks = int(total_rows / chunk_len) + 1\n",
    "                print(\"Total chunks to download:\", total_chunks)            \n",
    "\n",
    "                setup_and_create_table(create_params, api, tab_schemas)\n",
    "                params = request_params.copy()\n",
    "                for i in range(total_chunks):\n",
    "                    url = construct_url(api, params)\n",
    "                    data = request_data(url)\n",
    "                    data_list = data['response']['data']\n",
    "                    data_tuples = [tuple(d.values()) for d in data_list]\n",
    "                    schema = \", \".join(data_list[0].keys()).replace(\"-\", \"_\")\n",
    "\n",
    "                    populate_params['data'] = data_tuples\n",
    "                    populate_params['tab_name'] = api\n",
    "                    populate_params['schema'] = schema\n",
    "\n",
    "                    try:\n",
    "                        populate_table(**populate_params)\n",
    "                        # print(f\"Successfuly stored {len(data_tuples)} rows.\")\n",
    "\n",
    "                    except UniqueViolation as e:\n",
    "                        print(duplicates_msg)\n",
    "                    params['offset'] += chunk_len\n",
    "\n",
    "            if api == 'weather_hist':\n",
    "                data_dict = data['daily']\n",
    "                data_tuples = [values for values in zip(*data_dict.values())]\n",
    "                schema = \", \".join(data_dict.keys())\n",
    "\n",
    "                setup_and_create_table(create_params, api, tab_schemas)\n",
    "\n",
    "                populate_params['data'] = data_tuples\n",
    "                populate_params['tab_name'] = api\n",
    "                populate_params['schema'] = schema\n",
    "                try:\n",
    "                    populate_table(**populate_params)\n",
    "                    # print(f\"Successfuly stored {len(data_tuples)} rows.\")\n",
    "\n",
    "                except UniqueViolation as e:\n",
    "                    print(duplicates_msg)\n",
    "\n",
    "            if api == 'weather_latest':\n",
    "                data_dict = data['daily']\n",
    "                data_tuples = [values for values in zip(*data_dict.values())]\n",
    "                schema = \", \".join(data_dict.keys())\n",
    "                setup_and_create_table(create_params, api, tab_schemas)\n",
    "\n",
    "                populate_params['data'] = data_tuples\n",
    "                populate_params['tab_name'] = api\n",
    "                populate_params['schema'] = schema\n",
    "\n",
    "                try:\n",
    "                    populate_table(**populate_params)\n",
    "                    # print(f\"Successfuly stored {len(data_tuples)} rows.\")\n",
    "\n",
    "                except UniqueViolation as e:\n",
    "                    print(duplicates_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
