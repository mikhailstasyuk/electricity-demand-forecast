{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "from psycopg2.errors import DuplicateTable, OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    \"\"\"Parse command line arguments.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        args (argparse.Namespace) : Arguments object\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('-k', '--api_key', type=str, help=\"API key to use\", required=True)\n",
    "    parser.add_argument('-sd', '--start', type=str, help=\"Start date y-m-d\", required=True)\n",
    "    parser.add_argument('-ed', '--end', type=str, help=\"End date y-m-d\", required=True)\n",
    "    parser.add_argument('-to', '--save_to', type=str, help=\"Folder to save the data\", default=\".\")\n",
    "    parser.add_argument('-l', '--chunk_len', type=int, help=\"Number of rows in downloaded chunk\", default=5000)\n",
    "\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "    return args "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_data(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:  # Success\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(url):\n",
    "    \n",
    "    print(\"Getting data...\")\n",
    "    \n",
    "    data = request_data(url)\n",
    "    if data:\n",
    "        try:\n",
    "            if 'response' in data.keys():\n",
    "                print(data['response']['data'][0])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(\n",
    "    tab_name: str,\n",
    "    tab_schema: str,\n",
    "    dbname: str,\n",
    "    user: str,\n",
    "    password: str,\n",
    "    host: int,\n",
    "    port: int,\n",
    "    connect_timeout: int\n",
    ") -> None:\n",
    "    valid_tab_names = ['demand', 'weather_hist', 'weather_latest']\n",
    "    assert tab_name in valid_tab_names, \"Enter a valid table name.\"\n",
    "    \n",
    "    conn_params = {\n",
    "        'dbname': dbname,\n",
    "        'user': user,\n",
    "        'password': password,\n",
    "        'host': host,\n",
    "        'port': port,\n",
    "        'connect_timeout': connect_timeout\n",
    "    }\n",
    "    \n",
    "    # Connect to your postgres DB\n",
    "    try:\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "    \n",
    "    except OperationalError as e:\n",
    "        raise OperationalError(f\"Error connecting to the database: {e}\")\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Define the CREATE TABLE statement\n",
    "    create_table_query = f'''\n",
    "    CREATE TABLE {tab_name} (\n",
    "        id SERIAL PRIMARY KEY, \n",
    "        {tab_schema}\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        # Execute the query\n",
    "        cur.execute(create_table_query)\n",
    "\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "    except DuplicateTable as e:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        raise DuplicateTable(f\"The table {tab_name} already exists.\")\n",
    "    \n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_create_table(params, key, tab_schemas):\n",
    "    try:\n",
    "        tab_name, tab_schema = key, tab_schemas.get(key, -1)\n",
    "        params['tab_name'] = tab_name\n",
    "        params['tab_schema'] = tab_schema\n",
    "\n",
    "        create_table(**params)\n",
    "    except DuplicateTable as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_table(\n",
    "    data: list,\n",
    "    schema: list,\n",
    "    tab_name: str,\n",
    "    dbname: str,\n",
    "    user: str,\n",
    "    password: str,\n",
    "    host: int,\n",
    "    port: int,\n",
    "    connect_timeout: int\n",
    ") -> None:\n",
    "    \n",
    "    conn_params = {\n",
    "        'dbname': dbname,\n",
    "        'user': user,\n",
    "        'password': password,\n",
    "        'host': host,\n",
    "        'port': port,\n",
    "        'connect_timeout': connect_timeout\n",
    "    }\n",
    "    \n",
    "    # Connect to your postgres DB\n",
    "    try:\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "    \n",
    "    except OperationalError as e:\n",
    "        raise OperationalError(f\"Error connecting to the database: {e}\")\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Insert data\n",
    "    extras.execute_values(\n",
    "        cur,\n",
    "        f\"INSERT INTO {tab_name} ({schema}) VALUES %s\",\n",
    "        data\n",
    "    )\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_arguments()\n",
    "# api_key = args.api_key\n",
    "# start_date = args.start\n",
    "# end_date = args.end\n",
    "# output_path = args.save_to\n",
    "# chunk_len = args.chunk_len\n",
    "# offset = 0\n",
    "api_key = ''\n",
    "start_date = '2018-07-01'\n",
    "end_date = '2023-07-01'\n",
    "chunk_len = 100\n",
    "offset = 0\n",
    "\n",
    "urls = {\n",
    "    'demand': \n",
    "        f'https://api.eia.gov/v2/electricity/rto/' +\\\n",
    "        f'daily-region-sub-ba-data/data/?frequency=daily&data[0]=value' + \\\n",
    "        f'&facets[subba][]=ZONJ&start={start_date}&end={end_date}' + \\\n",
    "        f'&sort[0][column]=period&sort[0][direction]=asc&offset={offset}' + \\\n",
    "        f'&length={chunk_len}&api_key={api_key}',\n",
    "\n",
    "    'weather_hist': \n",
    "        f'https://archive-api.open-meteo.com/v1' + \\\n",
    "        f'/archive?latitude=52.52&longitude=13.41&start_date={start_date}' + \\\n",
    "        f'&end_date={end_date}&daily=weathercode,temperature_2m_max,' + \\\n",
    "        f'temperature_2m_min,temperature_2m_mean' + \\\n",
    "        f'&timezone=America%2FNew_York',\n",
    "    \n",
    "    'weather_latest': \n",
    "        f'https://api.open-meteo.com/v1/forecast?' + \\\n",
    "        f'latitude=52.52&longitude=13.41&hourly=temperature_2m&daily=' + \\\n",
    "        f'temperature_2m_max,temperature_2m_min&timezone=America%2F' + \\\n",
    "        f'New_York&past_days=7',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tab_population_params = {\n",
    "        'data': data_tuples,\n",
    "        'schema': schema,\n",
    "        'tabname': 'weather',\n",
    "        'dbname': 'db_demand',\n",
    "        'user': 'dbuser',\n",
    "        'password': '123',\n",
    "        'host': 'localhost',\n",
    "        'port': '5432',\n",
    "        'connect_timeout': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_schemas = {\n",
    "    'demand': \n",
    "        '''\n",
    "        subba VARCHAR(100),\n",
    "        period VARCHAR(100),\n",
    "        subba_name VARCHAR(100),\t\n",
    "        parent VARCHAR(100),\t\n",
    "        parent_name VARCHAR(100),\t\n",
    "        timezone VARCHAR(100),\t\n",
    "        value INTEGER,\t\n",
    "        value_units VARCHAR(100)\n",
    "        ''',\n",
    "\n",
    "    'weather_hist':\n",
    "        '''\n",
    "        time VARCHAR(100),\n",
    "        weathercode INTEGER,\n",
    "        temperature_2m_max\tREAL,\n",
    "        temperature_2m_min\tREAL,\n",
    "        temperature_2m_mean REAL\n",
    "        ''',\n",
    "\n",
    "    'weather_latest':\n",
    "        '''\n",
    "        time VARCHAR(100), \n",
    "        weathercode INTEGER, \n",
    "        temperature_2m_max REAL, \n",
    "        temperature_2m_min REAL, \n",
    "        temperature_2m_mean REAL\n",
    "        '''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table demand already exists.\n",
      "The table weather_hist already exists.\n",
      "The table weather_latest already exists.\n"
     ]
    }
   ],
   "source": [
    "general_params = {\n",
    "    'dbname': 'db_demand',\n",
    "    'user': 'dbuser',\n",
    "    'password': '123',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'connect_timeout': 5\n",
    "} \n",
    "\n",
    "create_params = {\n",
    "    'tab_name': None,\n",
    "    'tab_schema': None,\n",
    "    'dbname': general_params['dbname'],\n",
    "    'user':  general_params['user'],\n",
    "    'password':  general_params['password'],\n",
    "    'host':  general_params['host'],\n",
    "    'port':  general_params['port'],\n",
    "    'connect_timeout': general_params['connect_timeout']\n",
    "}\n",
    "\n",
    "populate_params = {\n",
    "    'data': None,\n",
    "    'schema': None,\n",
    "    'tab_name': None,\n",
    "    'dbname': general_params['dbname'],\n",
    "    'user':  general_params['user'],\n",
    "    'password':  general_params['password'],\n",
    "    'host':  general_params['host'],\n",
    "    'port':  general_params['port'],\n",
    "    'connect_timeout': general_params['connect_timeout']\n",
    "}\n",
    "\n",
    "for key, url in urls.items():\n",
    "    data = request_data(url)\n",
    "    if data:\n",
    "        if key == 'demand':\n",
    "            data_list = data['response']['data']\n",
    "            data_tuples = [tuple(d.values()) for d in data_list]\n",
    "            schema = \", \".join(data_list[0].keys()).replace(\"-\", \"_\")\n",
    "\n",
    "            setup_and_create_table(create_params, key, tab_schemas)\n",
    "\n",
    "            populate_params['data'] = data_tuples\n",
    "            populate_params['tab_name'] = key\n",
    "            populate_params['schema'] = schema\n",
    "\n",
    "            populate_table(**populate_params)\n",
    "            \n",
    "\n",
    "        if key == 'weather_hist':\n",
    "            data_dict = data['daily']\n",
    "            data_tuples = [values for values in zip(*data_dict.values())]\n",
    "            schema = \", \".join(data_dict.keys())\n",
    "            \n",
    "            setup_and_create_table(create_params, key, tab_schemas)\n",
    "            \n",
    "            populate_params['data'] = data_tuples\n",
    "            populate_params['tab_name'] = key\n",
    "            populate_params['schema'] = schema\n",
    "\n",
    "            populate_table(**populate_params)\n",
    "\n",
    "        if key == 'weather_latest':\n",
    "            data_dict = data['daily']\n",
    "            data_tuples = [values for values in zip(*data_dict.values())]\n",
    "            schema = \", \".join(data_dict.keys())\n",
    "\n",
    "            setup_and_create_table(create_params, key, tab_schemas)\n",
    "\n",
    "            populate_params['data'] = data_tuples\n",
    "            populate_params['tab_name'] = key\n",
    "            populate_params['schema'] = schema\n",
    "\n",
    "            populate_table(**populate_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
